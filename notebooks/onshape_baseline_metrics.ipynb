{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from brepmatching.data import BRepMatchingDataset\n",
    "from brepmatching.visualization import show_image, render_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_geo = BRepMatchingDataset('../../../brepmatching/GeoWithBaseline.zip','../../../brepmatching/GeoWithBaseline.pt',mode='test')\n",
    "ds_topo = BRepMatchingDataset('../../../brepmatching/TopoWithBaseline.zip','../../../brepmatching/TopoWithBaseline.pt',mode='test')\n",
    "ds_both = BRepMatchingDataset('../../../brepmatching/TopoAndGeoWithBaseline.zip','../../../brepmatching/TopoAndGeoWithBaseline.pt',mode='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_test_graphs = [ds_geo[i] for i in range(len(ds_geo))]\n",
    "topo_test_graphs = [ds_topo[i] for i in range(len(ds_topo))]\n",
    "both_test_graphs = [ds_both[i] for i in range(len(ds_both))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(geo_test_graphs, '../data/geo_test_set.pt')\n",
    "torch.save(topo_test_graphs, '../data/topo_test_set.pt')\n",
    "torch.save(both_test_graphs, '../data/both_test_set.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from automate import HetData\n",
    "from torch import is_tensor\n",
    "from matplotlib.figure import Figure\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from typing import Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOPO_KINDS: list[tuple[str, str, str]] = [\n",
    "  (\"faces\", \"face\", \"f\"),\n",
    "  # (\"loops\", \"loop\", \"l\"),\n",
    "  (\"edges\", \"edge\", \"e\"),\n",
    "  (\"vertices\", \"vertex\", \"v\")\n",
    "]\n",
    "\n",
    "def count_batches(data: HetData) -> int:\n",
    "    #Todo: is there a better way to count batches?\n",
    "    return int(max(data.left_faces_batch[-1].item(), data.right_faces_batch[-1].item())) + 1\n",
    "\n",
    "\n",
    "NUM_METRICS = 7\n",
    "METRIC_COLS = [\"true_pos\", \"true_neg\", \"missed\", \"incorrect\", \"false_pos\", # relative to nr\n",
    "               \"precision\", \"recall\"]\n",
    "\n",
    "def separate_batched_matches(matches: torch.Tensor,\n",
    "                             left_topo_batches: torch.Tensor,\n",
    "                             right_topo_batches: torch.Tensor) -> list[torch.Tensor]:\n",
    "    \"\"\"\n",
    "    given a 2xn tensor of matches, and the batches tensor of the left and right nodes into which the matches index,\n",
    "    return a list of b matches, with local indices within each instance\n",
    "    \"\"\"\n",
    "    match_list = []\n",
    "    num_batches = int(max(left_topo_batches[-1].item(), right_topo_batches[-1].item())) + 1\n",
    "    match_batches = left_topo_batches[matches[0]]\n",
    "    left_batch_counts = [(left_topo_batches == b).sum() for b in range(num_batches)]\n",
    "    right_batch_counts = [(right_topo_batches == b).sum() for b in range(num_batches)]\n",
    "    left_batch_offsets = []\n",
    "    right_batch_offsets = []\n",
    "    device = matches.device\n",
    "    offset = torch.tensor(0, device=device)\n",
    "    for size in left_batch_counts:\n",
    "        left_batch_offsets.append(offset.clone())\n",
    "        offset += size\n",
    "    offset = torch.tensor(0, device=device)\n",
    "    for size in right_batch_counts:\n",
    "        right_batch_offsets.append(offset.clone())\n",
    "        offset += size\n",
    "    \n",
    "    for b in range(num_batches):\n",
    "        filtered_matches = matches[:, match_batches == b]\n",
    "        filtered_matches[0] -= left_batch_offsets[b]\n",
    "        filtered_matches[1] -= right_batch_offsets[b]\n",
    "        assert(filtered_matches[0].numel() == 0 or (0 <= filtered_matches[0].min() and filtered_matches[0].max() < left_batch_counts[b]))\n",
    "        assert(filtered_matches[1].numel() == 0 or (0 <= filtered_matches[1].min() and filtered_matches[1].max() < right_batch_counts[b]))\n",
    "        match_list.append(filtered_matches)\n",
    "    return match_list\n",
    "\n",
    "def compute_metrics_impl(matches: torch.Tensor,\n",
    "                         gt_matches: torch.Tensor,\n",
    "                         n_topos_left: int,\n",
    "                         n_topos_right: int) -> np.ndarray:\n",
    "    device = matches.device\n",
    "\n",
    "    pred = torch.full((n_topos_right, ), -1, device=device)\n",
    "    pred[matches[1]] = matches[0]\n",
    "\n",
    "    gt = torch.full((n_topos_right, ), -1, device=device)\n",
    "    gt[gt_matches[1]] = gt_matches[0]\n",
    "\n",
    "    num_gt_matched = int((gt >= 0).sum().item())\n",
    "    num_gt_unmatched = n_topos_right - num_gt_matched\n",
    "\n",
    "    num_matched = int((pred >= 0).sum().item())\n",
    "\n",
    "    correct_mask = (pred == gt)\n",
    "    num_correct = int(correct_mask.sum().item())\n",
    "    num_true_pos = int(correct_mask.logical_and(pred >= 0).sum().item())\n",
    "    num_true_neg = num_correct - num_true_pos\n",
    "\n",
    "    incorrect_mask = (pred != gt)\n",
    "    num_incorrect = int(incorrect_mask.sum())\n",
    "    num_false_pos = int((gt[pred >= 0] == -1).sum())\n",
    "    num_missed = int((gt[pred == -1] >= 0).sum())\n",
    "    num_wrong_pos = num_incorrect - num_false_pos - num_missed\n",
    "\n",
    "    true_pos = (num_true_pos / n_topos_right) if n_topos_right > 0 else 0.0\n",
    "    true_neg = (num_true_neg / n_topos_right) if n_topos_right > 0 else 1.0\n",
    "    missed = (num_missed / n_topos_right) if n_topos_right > 0 else 0.0\n",
    "    incorrect = (num_wrong_pos / n_topos_right) if n_topos_right > 0 else 0.0\n",
    "    false_pos = (num_false_pos / n_topos_right) if n_topos_right > 0 else 0.0\n",
    "\n",
    "    precision = (num_true_pos / num_matched) if num_matched > 0 else 1.0\n",
    "    recall = (num_true_pos / num_gt_matched) if num_gt_matched > 0 else 1.0\n",
    "\n",
    "    return np.array([true_pos, true_neg, missed, incorrect, false_pos, precision, recall])\n",
    "\n",
    "def compute_metrics_from_matches(data: HetData, kinds: str, matches: torch.Tensor) -> np.ndarray:\n",
    "    gt_matches = data[f\"{kinds}_matches\"]       # assume non-empty\n",
    "\n",
    "    batch_left = data[f\"left_{kinds}_batch\"]\n",
    "    batch_right = data[f\"right_{kinds}_batch\"]\n",
    "\n",
    "    cur_matches_unbatched = separate_batched_matches(matches, batch_left, batch_right)\n",
    "    gt_matches_unbatched = separate_batched_matches(gt_matches, batch_left, batch_right)\n",
    "\n",
    "    n_batches = len(cur_matches_unbatched)\n",
    "\n",
    "    metrics = np.zeros(NUM_METRICS)\n",
    "\n",
    "    for b in range(n_batches):\n",
    "        n_topos_left = int((batch_left == b).sum().item())\n",
    "        n_topos_right = int((batch_right == b).sum().item())\n",
    "\n",
    "        cur_matches_b = cur_matches_unbatched[b]\n",
    "        gt_matches_b = gt_matches_unbatched[b]\n",
    "\n",
    "        cur_metrics = compute_metrics_impl(\n",
    "            cur_matches_b, gt_matches_b, n_topos_left, n_topos_right)\n",
    "        \n",
    "        metrics += cur_metrics\n",
    "    \n",
    "    metrics /= n_batches\n",
    "\n",
    "    return metrics\n",
    "\n",
    "###### PLOTTING ######\n",
    "\n",
    "def plot_metric(metric, thresholds, name):\n",
    "    fig = Figure(figsize=(8, 8))\n",
    "    ax = fig.add_subplot()\n",
    "    ax.plot(thresholds, metric)\n",
    "    ax.set_title(name + ' vs threshold')\n",
    "    ax.set_xlabel('Threshold')\n",
    "    ax.set_ylabel(name)\n",
    "    ax.set_ylim(-0.1, 1.1)\n",
    "    ax.grid()\n",
    "    return fig\n",
    "\n",
    "def plot_the_fives(true_pos: np.ndarray,\n",
    "                   true_neg: np.ndarray,\n",
    "                   missed: np.ndarray,\n",
    "                   incorrect: np.ndarray,\n",
    "                   false_pos: np.ndarray,\n",
    "                   thresholds: np.ndarray,\n",
    "                   title: str) -> Figure:\n",
    "    fig = Figure(figsize=(8, 8))\n",
    "    ax = fig.add_subplot()\n",
    "    ax.stackplot(thresholds, false_pos, incorrect, missed, true_neg, true_pos,\n",
    "                 labels=[\"False Positive\", \"Incorrect\", \"Missed\", \"True Negative\", \"True Positive\"],\n",
    "                 colors=[\"#BA5050\", \"#D4756C\", \"#D6CFB8\", \"#61B5CF\", \"#468CB8\"])\n",
    "    ax.legend(loc=\"upper left\")\n",
    "    ax.set_xlabel(\"Threshold\")\n",
    "    ax.set_title(title)\n",
    "    ax.set_ylim(-0.1, 1.1)\n",
    "    ax.grid()\n",
    "    return fig\n",
    "    \n",
    "    \n",
    "def plot_multiple_metrics(metrics: dict[str, np.ndarray], \n",
    "                          thresholds: np.ndarray,\n",
    "                          title: str):\n",
    "    fig = Figure(figsize=(8, 8))\n",
    "    ax = fig.add_subplot()\n",
    "    for j, key in enumerate(metrics):\n",
    "        if j == 0:\n",
    "            color = '#0000ff'\n",
    "        elif j == 1:\n",
    "            color = '#e08c24'\n",
    "        elif j == 2:\n",
    "            color = '#ff0000'\n",
    "        else:\n",
    "            color = None\n",
    "        ax.plot(thresholds, metrics[key], label=key, color=color)\n",
    "    ax.legend()\n",
    "    ax.set_xlabel('Threshold')\n",
    "    ax.set_title(title)\n",
    "    ax.set_ylim(-0.1, 1.1)\n",
    "    ax.grid()\n",
    "    return fig\n",
    "\n",
    "def plot_tradeoff(x, y, values, indices, xname, yname, suffix=''):\n",
    "    fig = Figure(figsize=(8, 8))\n",
    "    ax = fig.add_subplot()\n",
    "    ax.plot(x, y)\n",
    "\n",
    "    x_filtered = [x[i] for i in indices]\n",
    "    y_filtered = [y[i] for i in indices]\n",
    "    v_filtered = [values[i] for i in indices]\n",
    "    ax.scatter(x_filtered, y_filtered)\n",
    "    for xf, yf, vf in zip(x_filtered, y_filtered, v_filtered):\n",
    "        ax.annotate(str(round(vf,2)), (xf, yf))\n",
    "\n",
    "    ax.set_title(yname + ' VS ' + xname + suffix)\n",
    "    ax.set_xlabel(xname)\n",
    "    ax.set_ylabel(yname)\n",
    "    ax.set_xlim(-0.1, 1.1)\n",
    "    ax.set_ylim(-0.1, 1.1)\n",
    "    ax.grid()\n",
    "    return fig\n",
    "\n",
    "class Running_avg:\n",
    "    def __init__(self, dim):\n",
    "        self.state = np.zeros(dim)\n",
    "        self.count = 0.0\n",
    "    def __call__(self, value, weight):\n",
    "        self.state += value * weight\n",
    "        self.count += weight\n",
    "    def reset(self):\n",
    "        val = self.state / self.count if self.count > 0 else 0\n",
    "        self.state[:] = 0\n",
    "        self.count = 0.0\n",
    "        return val\n",
    "\n",
    "def logsumexp(x, keep_mask=None, add_one=True, dim=1):\n",
    "    if keep_mask is not None:\n",
    "        x = x.masked_fill(~keep_mask, -torch.inf)\n",
    "    if add_one:\n",
    "        zeros = torch.zeros(x.size(dim - 1), dtype=x.dtype, device=x.device).unsqueeze(\n",
    "            dim\n",
    "        )\n",
    "        x = torch.cat([x, zeros], dim=dim)\n",
    "\n",
    "    output = torch.logsumexp(x, dim=dim, keepdim=True)\n",
    "    if keep_mask is not None:\n",
    "        output = output.masked_fill(~torch.any(keep_mask, dim=dim, keepdim=True), 0)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ds_geo[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data.batch import Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "follow_batch=['left_vertices','right_vertices','left_edges', 'right_edges','left_faces','right_faces', 'faces_matches', 'edges_matches', 'vertices_matches']\n",
    "big_batch = Batch.from_data_list(geo_test_graphs,follow_batch=follow_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_face_metrics = compute_metrics_from_matches(big_batch, 'faces', big_batch.os_bl_faces_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Sets: 100%|██████████| 3/3 [00:20<00:00,  6.67s/it]\n"
     ]
    }
   ],
   "source": [
    "plots = []\n",
    "for name,test_set in tqdm((('Geo',geo_test_graphs), ('Topo', topo_test_graphs), ('Both', both_test_graphs)),'Test Sets'):\n",
    "    big_batch = Batch.from_data_list(test_set,follow_batch=follow_batch)\n",
    "    ds_plots = []\n",
    "    for topo_type in tqdm(['faces', 'edges', 'vertices'],'Match Sets', leave=False):\n",
    "        metrics = compute_metrics_from_matches(big_batch, topo_type, big_batch[f'os_bl_{topo_type}_matches'])\n",
    "        plot = plot_the_fives(*np.stack([metrics]*2)[:,:-2].T, np.array([0.0,1.0]),f'Onshape Baseline {name} ({topo_type})')\n",
    "        ds_plots.append(plot)\n",
    "        writer.add_figure(f'Onshape Baseline {name} ({topo_type})', plot)\n",
    "    plots.append(ds_plots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HetData(left_F=[3, 164], right_F=[3, 160], left_edge_export_ids=[48], right_edge_export_ids=[42], left_faces=[18, 62], right_faces=[16, 62], left_F_to_faces=[1, 164], right_F_to_faces=[1, 160], left_mcfs=[390, 6], right_mcfs=[344, 6], left_face_to_loop=[2, 18], right_face_to_loop=[2, 16], left_mcf_refs=[3, 390], right_mcf_refs=[3, 344], left_vertex_to_flat_topos=[2, 32], right_vertex_to_flat_topos=[2, 28], left_edge_samples=[48, 7, 10], right_edge_samples=[42, 7, 10], left_edge_to_flat_topos=[2, 48], right_edge_to_flat_topos=[2, 42], left_loop_export_ids=[18], right_loop_export_ids=[16], left_face_to_flat_topos=[2, 18], right_face_to_flat_topos=[2, 16], left_vertex_export_ids=[32], right_vertex_export_ids=[28], left_loops=[18, 38], right_loops=[16, 38], left_graph_idx=[1, 1], right_graph_idx=[1, 1], left_flat_topos=[116, 0], right_flat_topos=[102, 0], left_edges=[48, 72], right_edges=[42, 72], left_face_samples=[18, 9, 10, 10], right_face_samples=[16, 9, 10, 10], left_V_to_vertices=[2, 32], right_V_to_vertices=[2, 28], left_loop_to_edge=[2, 96], right_loop_to_edge=[2, 84], left_loop_to_flat_topos=[2, 18], right_loop_to_flat_topos=[2, 16], left_flat_topos_to_graph_idx=[1, 116], right_flat_topos_to_graph_idx=[1, 102], left_face_export_ids=[18], right_face_export_ids=[16], left_part_feat=[1, 20], right_part_feat=[1, 20], left_edge_to_vertex=[2, 96], right_edge_to_vertex=[2, 84], left_E_to_edges=[3, 200], right_E_to_edges=[3, 192], left_face_to_face=[3, 48], right_face_to_face=[3, 42], left_vertices=[32, 3], right_vertices=[28, 3], left_V=[84, 3], right_V=[82, 3], faces_matches=[2, 15], edges_matches=[2, 42], vertices_matches=[2, 28], bl_exact_faces_matches=[2, 0], bl_exact_edges_matches=[2, 0], bl_exact_vertices_matches=[2, 2], os_bl_faces_matches=[2, 13], os_bl_edges_matches=[2, 41], os_bl_vertices_matches=[2, 26], n_onshape_baseline_unmatched=[1])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('dummy_log/plots')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_figure(plots[0][0],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Sets: 100%|██████████| 3/3 [00:18<00:00,  6.19s/it]\n"
     ]
    }
   ],
   "source": [
    "for name,test_set in tqdm((('Geo',geo_test_graphs), ('Topo', topo_test_graphs), ('Both', both_test_graphs)),'Test Sets'):\n",
    "    big_batch = Batch.from_data_list(test_set,follow_batch=follow_batch)\n",
    "    for topo_type in tqdm(['faces', 'edges', 'vertices'],'Match Sets', leave=False):\n",
    "        metrics = compute_metrics_from_matches(big_batch, topo_type, big_batch[f'{topo_type}_matches'])\n",
    "        plot = plot_the_fives(*np.stack([metrics]*2)[:,:-2].T, np.array([0.0,1.0]),f'Ground Truth {name} ({topo_type})')\n",
    "        writer.add_figure(f'Ground Truth {name} ({topo_type})', plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Sets: 100%|██████████| 3/3 [00:19<00:00,  6.45s/it]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.makedirs('./metrics/exact/',exist_ok=True)\n",
    "for name,test_set in tqdm((('Geo',geo_test_graphs), ('Topo', topo_test_graphs), ('Both', both_test_graphs)),'Test Sets'):\n",
    "    big_batch = Batch.from_data_list(test_set,follow_batch=follow_batch)\n",
    "    for topo_type in tqdm(['faces', 'edges', 'vertices'],'Match Sets', leave=False):\n",
    "        metrics = compute_metrics_from_matches(big_batch, topo_type, big_batch[f'bl_exact_{topo_type}_matches'])\n",
    "        plot = plot_the_fives(*np.stack([metrics]*2)[:,:-2].T, np.array([0.0,1.0]),f'Exact Matching {name} ({topo_type})')\n",
    "        writer.add_figure(f'Exact Matching {name} ({topo_type})', plot)\n",
    "        plot.savefig(f'./metrics/exact/{name}_{topo_type}.png')\n",
    "\n",
    "writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brepmatching",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 | packaged by conda-forge | (main, Nov 22 2022, 08:45:29) \n[GCC 10.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a02bfb8f1d898def00b451032fe3fd61b197648e6e6357abb903b5b5d431d7b2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

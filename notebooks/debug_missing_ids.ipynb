{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from coincidence_matching import match_parts, get_export_id_types\n",
    "from zipfile import ZipFile\n",
    "import json\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from automate import Part\n",
    "import numpy as np\n",
    "import meshplot as mp\n",
    "from collections import Counter\n",
    "import torch\n",
    "\n",
    "from brepmatching.data import BRepMatchingDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "str(Path.home().joinpath('.config','onshapecreds.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://drive.google.com/file/d/1O7FajIOF5YT_1zW337pm6XE_B2gEhUUc\n",
    "https://drive.google.com/file/d/1OK4qyuUfSXqA-wd64p_f2pG0rxeeqXGM\n",
    "https://drive.google.com/file/d/1NnUBCkIUrYBTXvEC8IXGE4V2UNDTG6T6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gdrive_wget(FILEID, FILENAME):\n",
    "    return f\"wget --load-cookies /tmp/cookies.txt \\\"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id={FILEID}' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id={FILEID}\\\" -O {FILENAME} && rm -rf /tmp/cookies.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1NnUBCkIUrYBTXvEC8IXGE4V2UNDTG6T6' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\u0001\n",
      "/p')&id=1NnUBCkIUrYBTXvEC8IXGE4V2UNDTG6T6\" -O Topo.zip && rm -rf /tmp/cookies.txt\n"
     ]
    }
   ],
   "source": [
    "print(gdrive_wget('1NnUBCkIUrYBTXvEC8IXGE4V2UNDTG6T6','Topo.zip'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1O7FajIOF5YT_1zW337pm6XE_B2gEhUUc' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1O7FajIOF5YT_1zW337pm6XE_B2gEhUUc\" -O TopoAndGeo.zip && rm -rf /tmp/cookies.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from apikey.onshape import Onshape\n",
    "from pathlib import Path\n",
    "\n",
    "api = Onshape(stack='https://cad.onshape.com', creds=str(Path.home().joinpath('.config','onshapecreds.json')), logging=False)\n",
    "\n",
    "with ZipFile('../data/TopoandGeoV2FullRunWith100SamplesBaseline.zip','r') as zf:\n",
    "    with zf.open('data/baseline/allVariationsWithBaseline.csv','r') as f:\n",
    "        variations = pd.read_csv(f)\n",
    "    variations[:100]\n",
    "    variations = variations[variations.fail == 0]\n",
    "\n",
    "    failures = []\n",
    "    written = set()\n",
    "    with ZipFile('../data/redownload.zip','w') as wzf:\n",
    "        for i in tqdm(range(len(variations))):\n",
    "            d = variations.iloc[i]\n",
    "\n",
    "            response_orig = api.request(method='get', path=f'/api/partstudios/d/{d.did}/m/{d.mv_orig}/e/{d.eid}/parasolid', query={'includeExportIds':True})\n",
    "            response_var = api.request(method='get', path=f'/api/partstudios/d/{d.did}/m/{d.mv_var}/e/{d.eid}/parasolid', query={'includeExportIds':True})\n",
    "\n",
    "            if response_orig.status_code != 200 or response_var.status_code != 200:\n",
    "                failures.append(d)\n",
    "                continue\n",
    "            \n",
    "            orig_path = 'data/BrepsWithReference/' + d.ps_orig\n",
    "            var_path = 'data/BrepsWithReference/' + d.ps_var\n",
    "\n",
    "            if orig_path not in written:\n",
    "                with wzf.open(orig_path, 'w') as f:\n",
    "                    f.write(response_orig.text.encode('utf-8'))\n",
    "                written.add(orig_path)\n",
    "            if var_path not in written:\n",
    "                with wzf.open(var_path, 'w') as f:\n",
    "                    f.write(response_var.text.encode('utf-8'))\n",
    "                written.add(var_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with ZipFile('../data/TopoandGeoV2FullRunWith100SamplesBaseline.zip','r') as zf:\n",
    "\n",
    "with ZipFile('../data/GeoV2FullRunBaseline.zip','r') as zf:\n",
    "\n",
    "    with zf.open('data/baseline/allVariationsWithBaseline.csv','r') as f:\n",
    "        variations = pd.read_csv(f)\n",
    "\n",
    "    data = variations[:100]\n",
    "    data = data[(data.fail == 0) & (data.baselineNew != ' ') ]\n",
    "\n",
    "    incomplete = []\n",
    "    incompatible = []\n",
    "    diff_geo = []\n",
    "\n",
    "    m_f = []\n",
    "    m_e = []\n",
    "    m_v = []\n",
    "\n",
    "    A = []\n",
    "    B = []\n",
    "    M = []\n",
    "\n",
    "    for i in tqdm(range(len(data))):\n",
    "        d = data.iloc[i]\n",
    "        path_a = 'data/BrepsWithReference/' + d.ps_orig\n",
    "        path_b = 'data/baseline/' + d.baselineOrig\n",
    "\n",
    "        path_c = 'data/BrepsWithReference/' + d.ps_var\n",
    "        path_d = 'data/baseline/' + d.baselineNew\n",
    "        \n",
    "        path_gt_match = 'data/Matches/' + d.matchFile\n",
    "        path_bl_match = 'data/baseline/' + d.baselineMatch\n",
    "\n",
    "        with zf.open(path_a,'r') as f:\n",
    "            part_data_a = f.read().decode('utf-8')\n",
    "        with zf.open(path_b,'r') as f:\n",
    "            part_data_b = f.read().decode('utf-8')\n",
    "        with zf.open(path_b,'r') as f:\n",
    "            part_data_c = f.read().decode('utf-8')\n",
    "        with zf.open(path_b,'r') as f:\n",
    "            part_data_d = f.read().decode('utf-8')\n",
    "        with zf.open(path_gt_match,'r') as f:\n",
    "            gt_match = json.load(f)\n",
    "        with zf.open(path_bl_match, 'r') as f:\n",
    "            bl_match = json.load(f)\n",
    "\n",
    "        p_a = Part(part_data_a)\n",
    "        p_b = Part(part_data_b)\n",
    "        p_c = Part(part_data_c)\n",
    "        p_d = Part(part_data_d)\n",
    "\n",
    "        parts_have_same_num = len(p_a.brep.nodes.faces) == len(p_b.brep.nodes.faces) and len(p_a.brep.nodes.edges) == len(p_b.brep.nodes.edges) and len(p_a.brep.nodes.vertices) == len(p_b.brep.nodes.vertices)\n",
    "\n",
    "        matching = match_parts(part_data_a, part_data_b, True)\n",
    "        complete_matching = len(matching.face_matches) == len(p_a.brep.nodes.faces) and len(matching.edge_matches) == len(p_a.brep.nodes.edges) and len(matching.vertex_matches) == len(p_a.brep.nodes.vertices)\n",
    "\n",
    "        n_face_matches_missing = -len(matching.face_matches) + len(p_a.brep.nodes.faces)\n",
    "        n_edge_matches_missing = -len(matching.edge_matches) + len(p_a.brep.nodes.edges)\n",
    "        n_vertex_matches_missing =-len(matching.vertex_matches) + len(p_a.brep.nodes.vertices)\n",
    "\n",
    "        m_f.append(n_face_matches_missing)\n",
    "        m_e.append(n_edge_matches_missing)\n",
    "        m_v.append(n_vertex_matches_missing)\n",
    "\n",
    "        exact_geo = (p_a.mesh.V == p_b.mesh.V).all()\n",
    "\n",
    "        if not parts_have_same_num:\n",
    "            incompatible.append(i)\n",
    "        if not complete_matching:\n",
    "            incomplete.append(i)\n",
    "\n",
    "        if not exact_geo:\n",
    "            diff_geo.append(i)\n",
    "\n",
    "        A.append(p_a)\n",
    "        B.append(p_b)\n",
    "        M.append(matching)\n",
    "\n",
    "\n",
    "        # Exact matching of originals seems to work (and the tesselations are mostly identical!)\n",
    "        # Let's see how well we match the versions with variations:\n",
    "\n",
    "        var_matching = match_parts(part_data_c, part_data_d, True)\n",
    "\n",
    "        id_classes_a = get_export_id_types(part_data_a)\n",
    "        id_classes_b = get_export_id_types(part_data_b)\n",
    "        id_classes_c = get_export_id_types(part_data_c)\n",
    "        id_classes_d = get_export_id_types(part_data_d)\n",
    "\n",
    "        good_classes = ['PK_CLASS_face', 'PK_CLASS_edge', 'PK_CLASS_vertex']\n",
    "\n",
    "        #gt_topo_matches = [(v['val1'],v['val1']) for k,v in gt_match.items() if id_classes_a[v['val1']] in good_classes and id_classes_c[v['val2']] in good_classes]\n",
    "        bl_topo_matches = [(v['val1'],v['val1']) for k,v in bl_match.items() if id_classes_b[v['val1']] in good_classes and id_classes_d[v['val2']] in good_classes]\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'JF4' in part_data_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.link_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_b = Part(part_data_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len([e.export_id for e in part_b.brep.nodes.edges])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len([k for k,v in id_classes_b.items() if v == 'PK_CLASS_edge'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_classes_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.link_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.baselineMatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from apikey.onshape import Onshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = api.request(method='get', path=f'/api/partstudios/d/{d.did}/m/{d.mv_var}/e/{d.eid}/parasolid', query={'includeExportIds':True})#, query={'partIds':['JFD'],'includeExportIds':True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.text == part_data_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.mv_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.did"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.eid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_classes_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brepmatching",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "87142ede9042d04f934af2ae171157c789b6aae7f3fe10d44294683606c509dd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from coincidence_matching import match_parts\n",
    "from zipfile import ZipFile\n",
    "import json\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from automate import Part\n",
    "import numpy as np\n",
    "import meshplot as mp\n",
    "from collections import Counter\n",
    "import torch\n",
    "\n",
    "from brepmatching.data import BRepMatchingDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = BRepMatchingDataset('../data/GeoFullSet.zip','../data/GeoFullSet2.pt', test_size=0, val_size=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.load('../data/GeoFullSetCacheSplitNoNaN.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data['original_index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data['preprocessed_data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = data['preprocessed_data'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.bl_exact_vertices_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ZipFile('../data/GeoFullSet.zip','r') as zf:\n",
    "    with zf.open('data/VariationData/all_variations.csv','r') as f:\n",
    "        geo_data = pd.read_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(geo_data[geo_data.fail == 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(data['original_index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_precision(pred_matches,gt_matches):\n",
    "    v_exact = set((a.item(),b.item()) for a,b in pred_matches.T) \n",
    "    v_gt = set((a.item(),b.item()) for a,b in gt_matches.T)\n",
    "    if len(v_exact) > 0:\n",
    "        v_precision = (len(v_exact) - len(v_exact - v_gt) )/ len(v_exact)\n",
    "    else:\n",
    "        v_precision = 1.0\n",
    "    return v_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = []\n",
    "records = []\n",
    "for i,d in tqdm(enumerate(data['preprocessed_data'])):\n",
    "    \n",
    "    f_precision = get_precision(d.bl_exact_faces_matches, d.faces_matches)\n",
    "    e_precision = get_precision(d.bl_exact_edges_matches, d.edges_matches)\n",
    "    v_precision = get_precision(d.bl_exact_vertices_matches, d.vertices_matches)\n",
    "\n",
    "    orig_index = data['original_index'][i]\n",
    "    \n",
    "    records.append({\n",
    "        'index':i,\n",
    "        'original_index':orig_index,\n",
    "        'ps_orig':geo_data.ps_orig[orig_index],\n",
    "        'ps_var':geo_data.ps_var[orig_index],\n",
    "        'matchFile':geo_data.matchFile[orig_index],\n",
    "        'face_precision':f_precision,\n",
    "        'edge_precision':e_precision,\n",
    "        'vertex_precision':v_precision\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exact_match_precision = pd.DataFrame.from_records(records)\n",
    "exact_match_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exact_match_precision[exact_match_precision.edge_precision < 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vert_example = exact_match_precision[exact_match_precision.vertex_precision < 1].loc[128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vert_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vert_example.ps_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = exact_match_precision[exact_match_precision.vertex_precision < 1].iloc[8]\n",
    "with ZipFile('../data/GeoFullSet.zip','r') as zf:\n",
    "    path_orig = 'data/BrepsWithReference/' + ex.ps_orig\n",
    "    path_var = 'data/BrepsWithReference/' + ex.ps_var\n",
    "    path_match = 'data/Matches/' + ex.matchFile\n",
    "\n",
    "    with zf.open(path_orig, 'r') as f:\n",
    "        orig_data = f.read().decode('utf-8')\n",
    "    with zf.open(path_var, 'r') as f:\n",
    "        var_data = f.read().decode('utf-8')\n",
    "    with zf.open(path_match, 'r') as f:\n",
    "        gt_match = json.load(f)\n",
    "    gt_match = [(m['val1'], m['val2']) for m in gt_match.values()]\n",
    "    orig_part = Part(orig_data)\n",
    "    var_part = Part(var_data)\n",
    "    exact_matching = match_parts(orig_data, var_data, True)\n",
    "\n",
    "false_positives = set(exact_matching.vertex_matches) - set(gt_match)\n",
    "print('False Positives:')\n",
    "print(false_positives)\n",
    "\n",
    "\n",
    "orig_vert_0, var_vert_0 = list(false_positives)[0]\n",
    "\n",
    "orig_fp_verts = set(a for a,b in false_positives)\n",
    "var_fp_verts = set(b for a,b in false_positives)\n",
    "\n",
    "orig_exact_matched_verts = set(a for a,_ in exact_matching.vertex_matches)\n",
    "var_exact_matched_verts = set(b for _,b in exact_matching.vertex_matches)\n",
    "\n",
    "orig_v_id = [i for i,f in enumerate(orig_part.brep.nodes.vertices) if f.export_id == orig_vert_0][0]\n",
    "var_v_id = [i for i,f in enumerate(var_part.brep.nodes.vertices) if f.export_id == var_vert_0][0]\n",
    "\n",
    "orig_v_ids = [i for i,f in enumerate(orig_part.brep.nodes.vertices) if f.export_id in orig_exact_matched_verts]\n",
    "var_v_ids = [i for i,f in enumerate(var_part.brep.nodes.vertices) if f.export_id in var_exact_matched_verts]\n",
    "\n",
    "orig_fp_v = [i for i,f in enumerate(orig_part.brep.nodes.vertices) if f.export_id in orig_fp_verts]\n",
    "var_fp_v = [i for i,f in enumerate(var_part.brep.nodes.vertices) if f.export_id in var_fp_verts]\n",
    "\n",
    "print(geo_data.iloc[ex.original_index].link_orig)\n",
    "print(geo_data.iloc[ex.original_index].link_var)\n",
    "\n",
    "def joint_plot_verts(orig_part, var_part, verts_orig, verts_var, offset_idx = 0):\n",
    "\n",
    "    offset_a = orig_part.mesh.V.max(axis=0)\n",
    "    offset_b = var_part.mesh.V.min(axis=0)\n",
    "\n",
    "    for i in range(3):\n",
    "        if i != offset_idx:\n",
    "            offset_a[i] = 0\n",
    "            offset_b[i] = 0\n",
    "    offset_a *= 1.05\n",
    "    offset_b *= 1.05\n",
    "\n",
    "    verts_orig = set(verts_orig)\n",
    "    verts_var = set(verts_var)\n",
    "\n",
    "    verts_orig_idx = [i for i,v in enumerate(orig_part.mesh_topology.point_to_topology) if v in verts_orig]\n",
    "    verts_var_idx = [i for i,v in enumerate(var_part.mesh_topology.point_to_topology) if v in verts_var]\n",
    "\n",
    "    vert_locs = np.concatenate([orig_part.mesh.V[verts_orig_idx] + offset_a, var_part.mesh.V[verts_var_idx] + offset_b],axis=0)\n",
    "\n",
    "    return mp.plot(\n",
    "        np.concatenate(\n",
    "            [\n",
    "                orig_part.mesh.V + offset_a, \n",
    "                var_part.mesh.V + offset_b\n",
    "            ]),\n",
    "        np.concatenate(\n",
    "            [\n",
    "                orig_part.mesh.F, \n",
    "                (var_part.mesh.F + orig_part.mesh.V.shape[0])\n",
    "            ]),\n",
    "        return_plot=True\n",
    "    ).add_points(\n",
    "        vert_locs,\n",
    "        shading={'point_size':.005}\n",
    "    )\n",
    "joint_plot_verts(orig_part, var_part, orig_fp_v, var_fp_v , 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zf = ZipFile('../data/GeoFullSet.zip','r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_match == 'data/Matches/6e4ad64270ef3a3c41addd31_45614c7621587c07bd2ab7fa_9072204cb5aa216204767a09_default_jjdeiV02.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex.to_csv('bad_bolts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(exact_match_precision.face_precision < 1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = exact_match_precision[exact_match_precision.face_precision < 1].iloc[15]\n",
    "with ZipFile('../data/GeoFullSet.zip','r') as zf:\n",
    "    path_orig = 'data/BrepsWithReference/' + ex.ps_orig\n",
    "    path_var = 'data/BrepsWithReference/' + ex.ps_var\n",
    "    path_match = 'data/Matches/' + ex.matchFile\n",
    "\n",
    "    with zf.open(path_orig, 'r') as f:\n",
    "        orig_data = f.read().decode('utf-8')\n",
    "    with zf.open(path_var, 'r') as f:\n",
    "        var_data = f.read().decode('utf-8')\n",
    "    with zf.open(path_match, 'r') as f:\n",
    "        gt_match = json.load(f)\n",
    "    gt_match = [(m['val1'], m['val2']) for m in gt_match.values()]\n",
    "    orig_part = Part(orig_data)\n",
    "    var_part = Part(var_data)\n",
    "    exact_matching = match_parts(orig_data, var_data, True)\n",
    "\n",
    "false_positives = set(exact_matching.face_matches) - set(gt_match)\n",
    "print('False Positives:')\n",
    "print(false_positives)\n",
    "orig_face0, var_face0 = list(false_positives)[0]\n",
    "orig_exact_matched_faces = set(a for a,_ in exact_matching.face_matches)\n",
    "var_exact_matched_faces = set(b for _,b in exact_matching.face_matches)\n",
    "orig_f_id = [i for i,f in enumerate(orig_part.brep.nodes.faces) if f.export_id == orig_face0][0]\n",
    "var_f_id = [i for i,f in enumerate(var_part.brep.nodes.faces) if f.export_id == var_face0][0]\n",
    "orig_f_ids = [i for i,f in enumerate(orig_part.brep.nodes.faces) if f.export_id in orig_exact_matched_faces]\n",
    "var_f_ids = [i for i,f in enumerate(var_part.brep.nodes.faces) if f.export_id in var_exact_matched_faces]\n",
    "face_colors = np.concatenate([(orig_part.mesh_topology.face_to_topology == orig_f_id).astype(int),\n",
    "(var_part.mesh_topology.face_to_topology == var_f_id).astype(int)\n",
    "]).astype(float)\n",
    "\n",
    "all_face_colors = np.concatenate(\n",
    "[\n",
    "np.array([1.0 if i in orig_f_ids else 0.0 for i in orig_part.mesh_topology.face_to_topology]),\n",
    "np.array([1.0 if i in var_f_ids else 0.0 for i in var_part.mesh_topology.face_to_topology])\n",
    "]\n",
    ")\n",
    "print(geo_data.iloc[ex.original_index].link_orig)\n",
    "print(geo_data.iloc[ex.original_index].link_var)\n",
    "def joint_plot(orig_part, var_part, face_colors, offset_idx = 0):\n",
    "\n",
    "    offset_a = orig_part.mesh.V.max(axis=0)\n",
    "    offset_b = var_part.mesh.V.min(axis=0)\n",
    "\n",
    "    for i in range(3):\n",
    "        if i != offset_idx:\n",
    "            offset_a[i] = 0\n",
    "            offset_a[i] = 0\n",
    "    offset_a *= 1.05\n",
    "    offset_b *= 1.05\n",
    "\n",
    "    return mp.plot(\n",
    "        np.concatenate(\n",
    "            [\n",
    "                orig_part.mesh.V + offset_a, \n",
    "                var_part.mesh.V + offset_b\n",
    "            ]),\n",
    "        np.concatenate(\n",
    "            [\n",
    "                orig_part.mesh.F, \n",
    "                (var_part.mesh.F + orig_part.mesh.V.shape[0])\n",
    "            ]),\n",
    "        c = face_colors\n",
    "    )\n",
    "joint_plot(orig_part, var_part, face_colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def joint_plot(orig_part, var_part, face_colors):\n",
    "    return mp.plot(\n",
    "        np.concatenate(\n",
    "            [\n",
    "                orig_part.mesh.V, \n",
    "                (var_part.mesh.V)\n",
    "            ]),\n",
    "        np.concatenate(\n",
    "            [\n",
    "                orig_part.mesh.F, \n",
    "                (var_part.mesh.F + orig_part.mesh.V.shape[0])\n",
    "            ]),\n",
    "        c = np.concatenate([np.zeros(orig_part.mesh.F.shape[0]), np.ones(var_part.mesh.F.shape[0])]).astype(float)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_colors = np.concatenate([(orig_part.mesh_topology.face_to_topology == orig_f_id).astype(int),\n",
    "(var_part.mesh_topology.face_to_topology == var_f_id).astype(int)\n",
    "]).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(exact_matching.face_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_faces = set(f.export_id for f in orig_part.brep.nodes.faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(a,b) for a,b in gt_match if a in orig_faces]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(orig_part.mesh.F) + len(var_part.mesh.F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_face_colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zf = ZipFile('../data/TopoandGeoV2FullRunWith100SamplesBaseline.zip','r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[n for n in zf.namelist() if n.endswith('.csv')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with zf.open('data/baseline/allVariationsWithBaseline.csv','r') as f:\n",
    "    variations = pd.read_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = variations[:100]\n",
    "data = data[data.fail == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incomplete = []\n",
    "incompatible = []\n",
    "diff_geo = []\n",
    "\n",
    "m_f = []\n",
    "m_e = []\n",
    "m_v = []\n",
    "\n",
    "A = []\n",
    "B = []\n",
    "M = []\n",
    "\n",
    "for i in tqdm(range(len(data))):\n",
    "    d = data.iloc[i]\n",
    "    path_a = 'data/BrepsWithReference/' + d.ps_orig\n",
    "    path_b = 'data/baseline/' + d.baselineOrig\n",
    "    \n",
    "    with zf.open(path_a,'r') as f:\n",
    "        part_data_a = f.read().decode('utf-8')\n",
    "    with zf.open(path_b,'r') as f:\n",
    "        part_data_b = f.read().decode('utf-8')\n",
    "\n",
    "    p_a = Part(part_data_a)\n",
    "    p_b = Part(part_data_b)\n",
    "\n",
    "    parts_have_same_num = len(p_a.brep.nodes.faces) == len(p_b.brep.nodes.faces) and len(p_a.brep.nodes.edges) == len(p_b.brep.nodes.edges) and len(p_a.brep.nodes.vertices) == len(p_b.brep.nodes.vertices)\n",
    "\n",
    "    matching = match_parts(part_data_a, part_data_b, True)\n",
    "    complete_matching = len(matching.face_matches) == len(p_a.brep.nodes.faces) and len(matching.edge_matches) == len(p_a.brep.nodes.edges) and len(matching.vertex_matches) == len(p_a.brep.nodes.vertices)\n",
    "\n",
    "    n_face_matches_missing = -len(matching.face_matches) + len(p_a.brep.nodes.faces)\n",
    "    n_edge_matches_missing = -len(matching.edge_matches) + len(p_a.brep.nodes.edges)\n",
    "    n_vertex_matches_missing =-len(matching.vertex_matches) + len(p_a.brep.nodes.vertices)\n",
    "\n",
    "    m_f.append(n_face_matches_missing)\n",
    "    m_e.append(n_edge_matches_missing)\n",
    "    m_v.append(n_vertex_matches_missing)\n",
    "\n",
    "    exact_geo = (p_a.mesh.V == p_b.mesh.V).all()\n",
    "\n",
    "    if not parts_have_same_num:\n",
    "        incompatible.append(i)\n",
    "    if not complete_matching:\n",
    "        incomplete.append(i)\n",
    "\n",
    "    if not exact_geo:\n",
    "        diff_geo.append(i)\n",
    "\n",
    "    A.append(p_a)\n",
    "    B.append(p_b)\n",
    "    M.append(matching)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incomplete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(i,e) for i,e in enumerate(m_e) if e < 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 24\n",
    "p_a = A[k]\n",
    "p_b = B[k]\n",
    "matching = M[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e1 = [(id,count) for id,count in Counter([m[0] for m in matching.edge_matches]).items() if count > 1][0][0]\n",
    "e2 = [b for (a,b) in matching.edge_matches if a == e1 and b != e1][0]\n",
    "e1_i = [i for i,e in enumerate(p_a.brep.nodes.edges) if e.export_id == e1][0]\n",
    "e2_i = [i for i,e in enumerate(p_a.brep.nodes.edges) if e.export_id == e2][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E = []\n",
    "for i in range(p_a.mesh_topology.edge_to_topology.shape[0]):\n",
    "    for j in range(p_a.mesh_topology.edge_to_topology.shape[1]):\n",
    "        if p_a.mesh_topology.edge_to_topology[i,j] == e1_i:\n",
    "            E.append([p_a.mesh.F[i,(j-1)%3],p_a.mesh.F[i,j]])\n",
    "E = np.array(E)\n",
    "mp.plot(p_a.mesh.V, p_a.mesh.F,return_plot=True).add_edges(p_a.mesh.V, E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E = []\n",
    "for i in range(p_a.mesh_topology.edge_to_topology.shape[0]):\n",
    "    for j in range(p_a.mesh_topology.edge_to_topology.shape[1]):\n",
    "        if p_a.mesh_topology.edge_to_topology[i,j] == e2_i:\n",
    "            E.append([p_a.mesh.F[i,(j-1)%3],p_a.mesh.F[i,j]])\n",
    "E = np.array(E)\n",
    "mp.plot(p_a.mesh.V, p_a.mesh.F,return_plot=True).add_edges(p_a.mesh.V, E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E27 = []\n",
    "for t,k in edges_27:\n",
    "    v1 = p_a.mesh.F[i][(k-1)%3]\n",
    "    v2 = p_a.mesh.F[i][(k)]\n",
    "    E27.append([v1,v2])\n",
    "E27 = np.array(E27)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M[21].edge_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(m_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(A[23].mesh.V - B[23].mesh.V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(part_data_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(M[21].vertex_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(A[21].brep.nodes.vertices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_edge_examples(ex, offset_dir=0):\n",
    "    with ZipFile('../data/GeoFullSet.zip','r') as zf:\n",
    "        path_orig = 'data/BrepsWithReference/' + ex.ps_orig\n",
    "        path_var = 'data/BrepsWithReference/' + ex.ps_var\n",
    "        path_match = 'data/Matches/' + ex.matchFile\n",
    "\n",
    "        with zf.open(path_orig, 'r') as f:\n",
    "            orig_data = f.read().decode('utf-8')\n",
    "        with zf.open(path_var, 'r') as f:\n",
    "            var_data = f.read().decode('utf-8')\n",
    "        with zf.open(path_match, 'r') as f:\n",
    "            gt_match = json.load(f)\n",
    "        gt_match = [(m['val1'], m['val2']) for m in gt_match.values()]\n",
    "        orig_part = Part(orig_data)\n",
    "        var_part = Part(var_data)\n",
    "        exact_matching = match_parts(orig_data, var_data, True)\n",
    "\n",
    "    false_positives = set(exact_matching.edge_matches) - set(gt_match)\n",
    "    print('False Positives:')\n",
    "    print(false_positives)\n",
    "\n",
    "\n",
    "    #orig_edge_0, var_edge_0 = list(false_positives)[0]\n",
    "\n",
    "    orig_fp_edges = set(a for a,b in false_positives)\n",
    "    var_fp_edges = set(b for a,b in false_positives)\n",
    "\n",
    "    orig_exact_matched_edges = set(a for a,_ in exact_matching.edge_matches)\n",
    "    var_exact_matched_edges = set(b for _,b in exact_matching.edge_matches)\n",
    "\n",
    "    #orig_e_id = [i for i,f in enumerate(orig_part.brep.nodes.edges) if f.export_id == orig_vert_0][0]\n",
    "    #var_e_id = [i for i,f in enumerate(var_part.brep.nodes.edges) if f.export_id == var_vert_0][0]\n",
    "\n",
    "    orig_e_ids = [i for i,f in enumerate(orig_part.brep.nodes.edges) if f.export_id in orig_fp_edges]\n",
    "    var_e_ids = [i for i,f in enumerate(var_part.brep.nodes.edges) if f.export_id in var_fp_edges]\n",
    "\n",
    "\n",
    "\n",
    "    #orig_fp_e = [i for i,f in enumerate(orig_part.brep.nodes.edges) if f.export_id in orig_fp_verts]\n",
    "    #var_fp_e = [i for i,f in enumerate(var_part.brep.nodes.edges) if f.export_id in var_fp_verts]\n",
    "\n",
    "    print(geo_data.iloc[ex.original_index].link_orig)\n",
    "    print(geo_data.iloc[ex.original_index].link_var)\n",
    "\n",
    "    def joint_plot_edges(orig_part, var_part, e_ids_orig, e_ids_var, offset_idx = 0):\n",
    "\n",
    "        offset_a = orig_part.mesh.V.max(axis=0)\n",
    "        offset_b = var_part.mesh.V.min(axis=0)\n",
    "\n",
    "        for i in range(3):\n",
    "            if i != offset_idx:\n",
    "                offset_a[i] = 0\n",
    "                offset_b[i] = 0\n",
    "        offset_a *= 1.05\n",
    "        offset_b *= 1.05\n",
    "\n",
    "        e_ids_orig = set(e_ids_orig)\n",
    "        e_ids_var = set(e_ids_var)\n",
    "\n",
    "        E1 = []\n",
    "        for i in range(orig_part.mesh_topology.edge_to_topology.shape[0]):\n",
    "            for j in range(orig_part.mesh_topology.edge_to_topology.shape[1]):\n",
    "                if orig_part.mesh_topology.edge_to_topology[i,j] in e_ids_orig:\n",
    "                    E1.append([orig_part.mesh.F[i,(j-1)%3],orig_part.mesh.F[i,j]])\n",
    "        E2 = []\n",
    "        for i in range(var_part.mesh_topology.edge_to_topology.shape[0]):\n",
    "            for j in range(var_part.mesh_topology.edge_to_topology.shape[1]):\n",
    "                if var_part.mesh_topology.edge_to_topology[i,j] in e_ids_var:\n",
    "                    E2.append([var_part.mesh.F[i,(j-1)%3],var_part.mesh.F[i,j]])\n",
    "\n",
    "        E1 = np.array(E1)\n",
    "        E2 = np.array(E2)\n",
    "\n",
    "        E = np.concatenate([E1, E2+orig_part.mesh.V.shape[0]],axis=0)\n",
    "\n",
    "        V = np.concatenate(\n",
    "                [\n",
    "                    orig_part.mesh.V + offset_a,\n",
    "                    var_part.mesh.V + offset_b\n",
    "                ])\n",
    "        F = np.concatenate(\n",
    "                [\n",
    "                    orig_part.mesh.F,\n",
    "                    (var_part.mesh.F + orig_part.mesh.V.shape[0])\n",
    "                ])\n",
    "        return mp.plot(\n",
    "            V, F, return_plot=True\n",
    "        ).add_edges(V, E, shading={'point_size':.005})\n",
    "\n",
    "    joint_plot_edges(orig_part, var_part, orig_e_ids, var_e_ids, offset_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = exact_match_precision[exact_match_precision.edge_precision < 1].iloc[17]\n",
    "highlight_edge_examples(ex, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_edge_precision(ex):\n",
    "    with ZipFile('../data/GeoFullSet.zip','r') as zf:\n",
    "        path_orig = 'data/BrepsWithReference/' + ex.ps_orig\n",
    "        path_var = 'data/BrepsWithReference/' + ex.ps_var\n",
    "        path_match = 'data/Matches/' + ex.matchFile\n",
    "\n",
    "        with zf.open(path_orig, 'r') as f:\n",
    "            orig_data = f.read().decode('utf-8')\n",
    "        with zf.open(path_var, 'r') as f:\n",
    "            var_data = f.read().decode('utf-8')\n",
    "        with zf.open(path_match, 'r') as f:\n",
    "            gt_match = json.load(f)\n",
    "        gt_match = [(m['val1'], m['val2']) for m in gt_match.values()]\n",
    "        orig_part = Part(orig_data)\n",
    "        var_part = Part(var_data)\n",
    "        exact_matching = match_parts(orig_data, var_data, True)\n",
    "\n",
    "    false_positives = set(exact_matching.edge_matches) - set(gt_match)\n",
    "    return (len(exact_matching.edge_matches) - len(false_positives)) / len(exact_matching.edge_matches)\n",
    "\n",
    "redone_edge_precisions = []\n",
    "edge_fails = exact_match_precision[exact_match_precision.edge_precision < 1]\n",
    "for i in tqdm(range(len(edge_fails))):\n",
    "    ex = edge_fails.iloc[i]\n",
    "    redone_edge_precisions.append(compute_edge_precision(ex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(np.array(redone_edge_precisions) == 1) / len(redone_edge_precisions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.array(redone_edge_precisions) - edge_fails.edge_precision > 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brepmatching",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "87142ede9042d04f934af2ae171157c789b6aae7f3fe10d44294683606c509dd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

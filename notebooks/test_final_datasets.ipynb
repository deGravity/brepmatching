{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "import meshplot as mp\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import altair as alt\n",
    "\n",
    "\n",
    "from brepmatching.data import convert_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo = torch.load('../data/GeoFinal.pt')\n",
    "both = torch.load('../data/BothFinal.pt')\n",
    "topo = torch.load('../data/TopoFinal.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo[0]['data'].left_faces.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_converted = convert_cache(geo)\n",
    "topo_converted = convert_cache(topo)\n",
    "both_converted = convert_cache(both)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats_converted(cache):\n",
    "    lost_count = []\n",
    "    lost_pct = []\n",
    "    face_max = []\n",
    "    edge_max = []\n",
    "    vert_max = []\n",
    "\n",
    "    for data in cache['preprocessed_data']:\n",
    "        has_baseline = data.has_onshape_baseline[0].item()\n",
    "        if has_baseline:\n",
    "            baseline_lost = data.n_onshape_baseline_unmatched[0].item()\n",
    "            baseline_face = data.os_bl_faces_matches.shape[1]\n",
    "            baseline_edge = data.os_bl_edges_matches.shape[1]\n",
    "            baseline_vert = data.os_bl_vertices_matches.shape[1]\n",
    "            baseline_total = baseline_face + baseline_edge + baseline_vert\n",
    "            pct_lost = 0. if baseline_lost == 0 else baseline_lost / (baseline_total + baseline_lost)\n",
    "\n",
    "            face_max.append(\n",
    "                max(\n",
    "                    data.left_faces.abs().max().item() if len(data.left_faces) > 0 else 0., \n",
    "                    data.right_faces.abs().max().item()if len(data.right_faces) > 0 else 0.\n",
    "                )\n",
    "            )\n",
    "\n",
    "            edge_max.append(\n",
    "                max(\n",
    "                    data.left_edges.abs().max().item() if len(data.left_edges) > 0 else 0.,\n",
    "                    data.right_edges.abs().max().item()if len(data.right_edges) > 0 else 0.\n",
    "                )\n",
    "            )\n",
    "\n",
    "            vert_max.append(\n",
    "                max(\n",
    "                    data.left_vertices.abs().max().item() if len(data.left_vertices) > 0 else 0., \n",
    "                    data.right_vertices.abs().max().item() if len(data.right_vertices) > 0 else 0.\n",
    "                )\n",
    "            )\n",
    "\n",
    "            lost_count.append(baseline_lost)\n",
    "            lost_pct.append(pct_lost)\n",
    "            \n",
    "    lost_count = np.array(lost_count)\n",
    "    lost_pct = np.array(lost_pct)\n",
    "    face_max = np.array(face_max)\n",
    "    edge_max = np.array(edge_max)\n",
    "    vert_max = np.array(vert_max)\n",
    "\n",
    "    return {\n",
    "        'lost_count': lost_count,\n",
    "        'lost_pct': lost_pct,\n",
    "        'face_max': face_max,\n",
    "        'edge_max': edge_max,\n",
    "        'vert_max': vert_max\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_stats = get_stats_converted(geo_converted)\n",
    "topo_stats = get_stats_converted(topo_converted)\n",
    "both_stats = get_stats_converted(both_converted)\n",
    "\n",
    "def filter_count(stats, face_thresh = 200, edge_thresh = 200, vert_thresh = 5):\n",
    "    filt_lost = stats['lost_count'] == 0\n",
    "    filt_face = stats['face_max'] < face_thresh\n",
    "    filt_edge = stats['edge_max'] < edge_thresh\n",
    "    filt_vert = stats['vert_max'] < vert_thresh\n",
    "\n",
    "    filt = filt_lost & filt_face & filt_edge & filt_vert\n",
    "\n",
    "    return filt.sum()\n",
    "\n",
    "def filter_records(gt, vt):\n",
    "    return [{\n",
    "        'geo_thresh': gt,\n",
    "        'vert_thresh': vt,\n",
    "        'ds':'geo',\n",
    "        'count': filter_count(geo_stats, gt, gt, vt),\n",
    "    },\n",
    "    {\n",
    "        'geo_thresh': gt,\n",
    "        'vert_thresh': vt,\n",
    "        'ds':'topo',\n",
    "        'count': filter_count(topo_stats, gt, gt, vt)\n",
    "    },\n",
    "    {\n",
    "        'geo_thresh': gt,\n",
    "        'vert_thresh': vt,\n",
    "        'ds':'both',\n",
    "        'count': filter_count(both_stats, gt, gt, vt)\n",
    "    }\n",
    "    ]\n",
    "\n",
    "f_records = []\n",
    "for gt in np.linspace(0,1000,1001):\n",
    "    for vt in [4]:#np.linspace(0,20,21):\n",
    "        f_records += filter_records(gt,vt)\n",
    "df = pd.DataFrame.from_records(f_records)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.data_transformers.disable_max_rows()\n",
    "\n",
    "alt.Chart(df).mark_line().encode(\n",
    "    x='geo_thresh',\n",
    "    y='count',\n",
    "    color='vert_thresh:O',\n",
    "    column='ds'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.abs(np.abs(geo_stats['face_max'][geo_stats['face_max'] > 400]) - 500) < .1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len([i for i,d in enumerate(geo) if d['reason'] == 'ok'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len([i for i,d in enumerate(both) if d['reason'] == 'ok'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo[0]['data'].has_onshape_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(ds):\n",
    "    lost_count = []\n",
    "    lost_pct = []\n",
    "    face_max = []\n",
    "    edge_max = []\n",
    "    vert_max = []\n",
    "\n",
    "    for d in ds:\n",
    "        if d['reason'] == 'ok':\n",
    "            data = d['data']\n",
    "            has_baseline = data.has_onshape_baseline[0].item()\n",
    "            if has_baseline:\n",
    "                baseline_lost = data.n_onshape_baseline_unmatched[0].item()\n",
    "                baseline_face = data.os_bl_faces_matches.shape[1]\n",
    "                baseline_edge = data.os_bl_edges_matches.shape[1]\n",
    "                baseline_vert = data.os_bl_vertices_matches.shape[1]\n",
    "                baseline_total = baseline_face + baseline_edge + baseline_vert\n",
    "                pct_lost = 0. if baseline_lost == 0 else baseline_lost / (baseline_total + baseline_lost)\n",
    "\n",
    "                face_max.append(\n",
    "                    max(\n",
    "                        data.left_faces.abs().max().item() if len(data.left_faces) > 0 else 0., \n",
    "                        data.right_faces.abs().max().item()if len(data.right_faces) > 0 else 0.\n",
    "                    )\n",
    "                )\n",
    "\n",
    "                edge_max.append(\n",
    "                    max(\n",
    "                        data.left_edges.abs().max().item() if len(data.left_edges) > 0 else 0.,\n",
    "                        data.right_edges.abs().max().item()if len(data.right_edges) > 0 else 0.\n",
    "                    )\n",
    "                )\n",
    "\n",
    "                vert_max.append(\n",
    "                    max(\n",
    "                        data.left_vertices.abs().max().item() if len(data.left_vertices) > 0 else 0., \n",
    "                        data.right_vertices.abs().max().item() if len(data.right_vertices) > 0 else 0.\n",
    "                    )\n",
    "                )\n",
    "\n",
    "                lost_count.append(baseline_lost)\n",
    "                lost_pct.append(pct_lost)\n",
    "    lost_count = np.array(lost_count)\n",
    "    lost_pct = np.array(lost_pct)\n",
    "    face_max = np.array(face_max)\n",
    "    edge_max = np.array(edge_max)\n",
    "    vert_max = np.array(vert_max)\n",
    "\n",
    "    return {\n",
    "        'lost_count': lost_count,\n",
    "        'lost_pct': lost_pct,\n",
    "        'face_max': face_max,\n",
    "        'edge_max': edge_max,\n",
    "        'vert_max': vert_max\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in geo:\n",
    "    if d['reason'] == 'ok':\n",
    "        d['geo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foobar = [\n",
    "    {'a':{'b':np.array([1,0,0])}}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_stats = get_stats(geo)\n",
    "topo_stats = get_stats(topo)\n",
    "both_stats = get_stats(both)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_count(stats, face_thresh = 200, edge_thresh = 200, vert_thresh = 5):\n",
    "    filt_lost = stats['lost_count'] == 0\n",
    "    filt_face = stats['face_max'] < face_thresh\n",
    "    filt_edge = stats['edge_max'] < edge_thresh\n",
    "    filt_vert = stats['vert_max'] < vert_thresh\n",
    "\n",
    "    filt = filt_lost & filt_face & filt_edge & filt_vert\n",
    "\n",
    "    return filt.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_count(stats, face_thresh = 200, edge_thresh = 200, vert_thresh = 5):\n",
    "    filt_lost = stats['lost_count'] == 0\n",
    "    filt_face = stats['face_max'] < face_thresh\n",
    "    filt_edge = stats['edge_max'] < edge_thresh\n",
    "    filt_vert = stats['vert_max'] < vert_thresh\n",
    "\n",
    "    filt = filt_lost & filt_face & filt_edge & filt_vert\n",
    "\n",
    "    return filt.sum()\n",
    "\n",
    "def filter_records(gt, vt):\n",
    "    return [{\n",
    "        'geo_thresh': gt,\n",
    "        'vert_thresh': vt,\n",
    "        'ds':'geo',\n",
    "        'count': filter_count(geo_stats, gt, gt, vt),\n",
    "    },\n",
    "    {\n",
    "        'geo_thresh': gt,\n",
    "        'vert_thresh': vt,\n",
    "        'ds':'topo',\n",
    "        'count': filter_count(topo_stats, gt, gt, vt)\n",
    "    },\n",
    "    {\n",
    "        'geo_thresh': gt,\n",
    "        'vert_thresh': vt,\n",
    "        'ds':'both',\n",
    "        'count': filter_count(both_stats, gt, gt, vt)\n",
    "    }\n",
    "    ]\n",
    "\n",
    "f_records = []\n",
    "for gt in np.linspace(0,1000,1001):\n",
    "    for vt in np.linspace(0,20,21):\n",
    "        f_records += filter_records(gt,vt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expert['preprocessed_data'][0].left_vertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from brepmatching.data import ParallelPreprocessor, load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expert = load_data('../data/ExpertDataWithBaseline.zip', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expert_face_max = []\n",
    "expert_edge_max = []\n",
    "expert_vert_max = []\n",
    "for data in expert['preprocessed_data']:\n",
    "    expert_face_max.append(\n",
    "        max(\n",
    "            data.left_faces[:,:15].abs().max().item() if len(data.left_faces) > 0 else 0., \n",
    "            data.right_faces[:,:15].abs().max().item()if len(data.right_faces) > 0 else 0.,\n",
    "            data.left_faces[:,18:].abs().max().item() if len(data.left_faces) > 0 else 0., \n",
    "            data.right_faces[:,18:].abs().max().item()if len(data.right_faces) > 0 else 0.\n",
    "        )\n",
    "    )\n",
    "\n",
    "    expert_edge_max.append(\n",
    "        max(\n",
    "            data.left_edges.abs().max().item() if len(data.left_edges) > 0 else 0.,\n",
    "            data.right_edges.abs().max().item()if len(data.right_edges) > 0 else 0.\n",
    "        )\n",
    "    )\n",
    "\n",
    "    expert_vert_max.append(\n",
    "        max(\n",
    "            data.left_vertices.abs().max().item() if len(data.left_vertices) > 0 else 0., \n",
    "            data.right_vertices.abs().max().item() if len(data.right_vertices) > 0 else 0.\n",
    "        )\n",
    "    )\n",
    "\n",
    "expert_face_max = np.array(expert_face_max)\n",
    "expert_edge_max = np.array(expert_edge_max)\n",
    "expert_vert_max = np.array(expert_vert_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = expert['preprocessed_data'][15].left_edges\n",
    "\n",
    "for i in range(f.shape[0]):\n",
    "    for j in range(f.shape[1]):\n",
    "        if f[i,j] == 500:\n",
    "            print(f'{i},{j}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(f == 500).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expert['original_index'][15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(expert_edge_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(geo_stats['lost_count'] > 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(topo_stats['lost_count'] > 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(both_stats['lost_count'] > 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(geo_stats['vert_max'], range(0,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(topo_stats['face_max'], range=(0,1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(both_stats['face_max'], range=(0,300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_max = geo_stats['face_max']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_parts = np.arange(len(face_max))[((face_max > 480) & (face_max < 510))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.left_V.max(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.left_V.min(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = (geo[large_parts[0]]['data'].left_faces)\n",
    "\n",
    "for i in range(f.shape[0]):\n",
    "    for j in range(f.shape[1]):\n",
    "        if f[i,j] == -500:\n",
    "            print(f'{i},{j}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(f == -500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_stats = []\n",
    "for i in large_parts:\n",
    "    data = geo[i]['data']\n",
    "    if data is None:\n",
    "        continue\n",
    "    V = data.left_V.numpy()\n",
    "    center = (V.min(axis=0) + V.max(axis=0)) / 2\n",
    "    size = V.max(axis=0) - V.min(axis=0)\n",
    "    face_max = data.left_faces.abs().max()\n",
    "    edge_max = data.left_edges.abs().max()\n",
    "    vert_max = data.left_vertices.abs().max() if len(data.left_vertices) > 0 else 0\n",
    "    big_stats.append({\n",
    "        'i':i,\n",
    "        'center':center,\n",
    "        'size':size,\n",
    "        'face_max':face_max,\n",
    "        'edge_max':edge_max,\n",
    "        'vert_max':vert_max\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = large_parts[25]\n",
    "\n",
    "data = geo[i]['data']\n",
    "\n",
    "mp.plot(data.left_V.numpy(), data.left_F.T.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brepmatching",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "87142ede9042d04f934af2ae171157c789b6aae7f3fe10d44294683606c509dd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from coincidence_matching import match_parts, get_export_id_types, match_parts_dict\n",
    "from zipfile import ZipFile\n",
    "import json\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from automate import Part\n",
    "import numpy as np\n",
    "import meshplot as mp\n",
    "from collections import Counter\n",
    "import torch\n",
    "\n",
    "from apikey.onshape import Onshape\n",
    "\n",
    "from brepmatching.data import BRepMatchingDataset\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "str(Path.home().joinpath('.config','onshapecreds.json'))\n",
    "\n",
    "api = Onshape(stack='https://cad.onshape.com', creds=str(Path.home().joinpath('.config','onshapecreds.json')), logging=False)\n",
    "\n",
    "\n",
    "def dowload_part(did, mv, eid):\n",
    "    response = api.request(\n",
    "        method='get', \n",
    "        path=f'/api/partstudios/d/{did}/m/{mv}/e/{eid}/parasolid', query={'includeExportIds':True})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from coincidence_matching import match_parts, get_export_id_types, match_parts_dict\n",
    "from zipfile import ZipFile\n",
    "import json\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from automate import Part\n",
    "import numpy as np\n",
    "import meshplot as mp\n",
    "from collections import Counter\n",
    "import torch\n",
    "from automate import Part\n",
    "from brepmatching.data import BRepMatchingDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from apikey.onshape import Onshape\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ZipFile('../data/TopoandGeoV2FullRunWith100SamplesBaseline.zip','r') as zf:\n",
    "    with zf.open('data/baseline/allVariationsWithBaseline.csv','r') as f:\n",
    "        variations = pd.read_csv(f)\n",
    "    variations[:100]\n",
    "    variations = variations[variations.fail == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_orig_path = 'data/BrepsWithReference/' + variations.iloc[0].ps_orig\n",
    "primary_var_path = 'data/BrepsWithReference/' + variations.iloc[0].ps_var\n",
    "primary_match_path = 'data/Matches/' + variations.iloc[0].matchFile\n",
    "\n",
    "baseline_orig_path = '../data/benTestBrep1.x_t'\n",
    "baseline_var_path = '../data/benTestBrep2.x_t'\n",
    "baseline_match_path = '../data/benTestMatch.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ZipFile('../data/TopoandGeoV2FullRunWith100SamplesBaseline.zip','r') as zf:\n",
    "    with zf.open(primary_orig_path,'r') as f:\n",
    "        primary_orig_data = f.read().decode('utf-8')\n",
    "    with zf.open(primary_var_path,'r') as f:\n",
    "        primary_var_data = f.read().decode('utf-8')\n",
    "    with zf.open(primary_match_path,'r') as f:\n",
    "        primary_match = json.load(f)\n",
    "\n",
    "primary_orig_part = Part(primary_orig_data)\n",
    "primary_var_part = Part(primary_var_data)\n",
    "\n",
    "baseline_orig_part = Part(baseline_orig_path)\n",
    "baseline_var_part = Part(baseline_var_path)\n",
    "with open(baseline_match_path, 'r') as f:\n",
    "    baseline_match = json.load(f)\n",
    "\n",
    "primary_orig_export_ids = get_export_id_types(primary_orig_data)\n",
    "primary_var_export_ids = get_export_id_types(primary_var_data)\n",
    "\n",
    "baseline_orig_export_ids = get_export_id_types(baseline_orig_path)\n",
    "baseline_var_export_ids = get_export_id_types(baseline_var_path)\n",
    "\n",
    "orig_exact_matching = match_parts(baseline_orig_path, primary_orig_data, True)\n",
    "var_exact_matching = match_parts(baseline_var_path, primary_var_data, True)\n",
    "\n",
    "orig_exact_matching_dict = match_parts_dict(baseline_orig_path, primary_orig_data, True)\n",
    "var_exact_matching_dict = match_parts_dict(baseline_var_path, primary_var_data, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "types_to_match = ['PK_CLASS_face', 'PK_CLASS_edge', 'PK_CLASS_vertex']\n",
    "type_counts = np.zeros((3,))\n",
    "translated_matching = {}\n",
    "for k, match in baseline_match.items():\n",
    "    orig_export_id = match['val1']\n",
    "    var_export_id = match['val2']\n",
    "    assert(baseline_orig_export_ids[orig_export_id] == baseline_var_export_ids[var_export_id])\n",
    "    if baseline_var_export_ids[var_export_id] in types_to_match:\n",
    "        t = types_to_match.index(baseline_var_export_ids[var_export_id])\n",
    "        type_counts[t] = type_counts[t] + 1\n",
    "        new_var_export_id = var_exact_matching_dict[var_export_id]\n",
    "        translated_matching[k] = {'val1':orig_export_id, 'val2':new_var_export_id}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "87142ede9042d04f934af2ae171157c789b6aae7f3fe10d44294683606c509dd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
